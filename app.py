from langchain_openai import ChatOpenAI
from langchain.schema import HumanMessage, AIMessage
from dotenv import load_dotenv, find_dotenv

# ğŸ” NaÄtenÃ­ API klÃ­Äe
load_dotenv(find_dotenv(), override=True)

# âš™ï¸ NastavenÃ­ jednotlivÃ½ch agentÅ¯ a jejich rolÃ­
llm1_settings = {"model": "gpt-3.5-turbo", "temperature": 0.7}
llm2_settings = {"model": "gpt-3.5-turbo", "temperature": 0.7}
llm3_settings = {"model": "gpt-3.5-turbo", "temperature": 0.7,}
moderator_llm_settings = {"model": "gpt-3.5-turbo", "temperature": 0.7}

# Inicializace agentÅ¯ pomocÃ­ jmÃ©na agenta, modelu a role
agents = [
    ("Alice", ChatOpenAI(**llm1_settings), "Jsi technologickÃ½ optimista. ZdÅ¯razÅˆujeÅ¡ pÅ™Ã­nosy umÄ›lÃ© inteligence a nesouhlasÃ­Å¡ s pÅ™ehnanÃ½mi obavami."), 
    ("Bob", ChatOpenAI(**llm2_settings), "Jsi etickÃ½ skeptik. PoukazujeÅ¡ na rizika a slabiny AI. VyvracÃ­Å¡ pÅ™ehnanÃ½ optimismus."),
    ("Eva", ChatOpenAI(**llm3_settings), "Jsi akademickÃ½ vyvaÅ¾ovaÄ. SnaÅ¾Ã­Å¡ se obÄ› pÅ™edchozÃ­ nÃ¡zory zasadit do vÄ›deckÃ©ho kontextu a zpochybÅˆujeÅ¡ jejich argumenty.")
]

moderator = ChatOpenAI(**moderator_llm_settings)

# PoÄÃ¡teÄnÃ­ tÃ©ma konverzace
init_prompt = "DneÅ¡nÃ­ tÃ©ma je: Budoucnost umÄ›lÃ© inteligence. Diskutujte."

# Inicializace kontextu zprÃ¡v (chat history)
full_history = [HumanMessage(content=init_prompt)]
summary_history = []

# PoÄet komunikaÄnÃ­ch iteracÃ­ (bÄ›hem iterace se vystÅ™Ã­dajÃ­ vÅ¡echny modely)
conversation_rounds = 3

# PomocnÃ¡ funkce pro 1 odpovÄ›Ä agenta
def run_turn(name, model, role, round_history, full_history):
    prompt = HumanMessage(content=f"{role}\nDiskutuj k tÃ©matu a reaguj na pÅ™edchozÃ­ pÅ™Ã­spÄ›vky.")
    response = model.invoke(round_history + [prompt])
    print(f"\nğŸ§  {name}: {response.content}")
    round_history.append(AIMessage(content=response.content))
    full_history.append(AIMessage(content=response.content))

# Simulace konverzace
for round_idx in range(conversation_rounds):
    print(f"\nğŸ—¨ï¸  Kolo {round_idx+1}")

    # historie pouze pro aktuÃ¡lnÃ­ kolo
    round_history = []

    # Agenti diskutujÃ­
    for name, model, role in agents:
        run_turn(name, model, role, round_history, full_history)

    # ModerÃ¡tor shrnuje
    summary_prompt = HumanMessage(content=f"Jako moderÃ¡tor shrÅˆ diskusi tohoto kola (kolo {round_idx+1}).")
    moderator_response = moderator.invoke(round_history + [summary_prompt])
    print(f"\nâœï¸ ModerÃ¡tor (shrnutÃ­ kola {round_idx+1}): {moderator_response.content}")
    summary_history.append(AIMessage(content=f"[ShrnutÃ­ kola {round_idx+1}] {moderator_response.content}"))